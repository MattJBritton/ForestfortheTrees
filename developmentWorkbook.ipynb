{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from __future__ import division\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "from itertools import product\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable(\"notebook\")\n",
    "import ipywidgets as wid\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestForTheTrees:\n",
    "    \n",
    "    DEFAULT_LEARNING_RATE = 1.\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.dataset = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.feature_names = None\n",
    "        self.feature_locs = None\n",
    "        self.feature_ranges = {}\n",
    "        self.target_type = None\n",
    "        self.classifier_type = None\n",
    "        self.classifier = None\n",
    "        self.mean_prediction = None\n",
    "        self.no_predictor_features = []\n",
    "        self.oned_features = []   \n",
    "        self.binned_data = None\n",
    "        self.sample_size = None\n",
    "        self.num_tiles = None\n",
    "        self.quantiles = None\n",
    "        self.learning_rate = self.DEFAULT_LEARNING_RATE\n",
    "        self.predictions_base = None\n",
    "        self.chart_components = {}\n",
    "        self.explanation_components = {}\n",
    "        self.base_explanation = []\n",
    "        self.evaluation_details = []\n",
    "        self.base_components = []\n",
    "        self.explanation = []\n",
    "        self.cache = {}\n",
    "        \n",
    "    def __init__(self, dataset, sample_size, num_tiles, quantiles, learning_rate):\n",
    "        \n",
    "        self.classifier_type = None\n",
    "        self.classifier = None\n",
    "        self.mean_prediction = None\n",
    "        self.no_predictor_features = []\n",
    "        self.oned_features = []   \n",
    "        self.binned_data = None\n",
    "        self.sample_size = sample_size #may be set to none here, will be handled in load_dataset()\n",
    "        self.num_tiles = num_tiles\n",
    "        self.quantiles = quantiles\n",
    "        self.learning_rate = learning_rate\n",
    "        self.predictions_base = None\n",
    "        self.chart_components = {}\n",
    "        self.explanation_components = {}\n",
    "        self.base_explanation = []\n",
    "        self.evaluation_details = []\n",
    "        self.base_components = []\n",
    "        self.explanation = []\n",
    "        self.cache = {}\n",
    "        self.load_dataset(dataset)\n",
    "        \n",
    "    def set_sample_size(self, new_size):\n",
    "        self.sample_size = new_size\n",
    "    \n",
    "    def get_dataset(self, dataset):\n",
    "        \n",
    "        if dataset == \"bike\":\n",
    "            def _datestr_to_timestamp(s):\n",
    "                return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%d\").timetuple())\n",
    "\n",
    "            dataLoad = pd.read_csv('data/bike.csv')\n",
    "            dataLoad['dteday'] = dataLoad['dteday'].apply(_datestr_to_timestamp)\n",
    "            dataLoad = pd.get_dummies(dataLoad, prefix=[\"weathersit\"], columns=[\"weathersit\"], drop_first = False)\n",
    "\n",
    "            #de-normalize data to produce human-readable features.\n",
    "            #Original range info from http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n",
    "            dataLoad[\"hum\"] = dataLoad[\"hum\"].apply(lambda x: x*100.)\n",
    "            dataLoad[\"windspeed\"] = dataLoad[\"windspeed\"].apply(lambda x: x*67.)\n",
    "            #convert Celsius to Fahrenheit\n",
    "            dataLoad[\"temp\"] = dataLoad[\"temp\"].apply(lambda x: (x*47. - 8)*9/5 +32)\n",
    "            dataLoad[\"atemp\"] = dataLoad[\"atemp\"].apply(lambda x: (x*66. - 16)*9/5 + 32)\n",
    "\n",
    "            #rename features to make them interpretable for novice users\n",
    "            feature_names_dict = {\n",
    "                \"yr\":\"First or Second Year\", \n",
    "                \"season\":\"Season\", \n",
    "                \"hr\":\"Hour of Day\", \n",
    "                \"workingday\":\"Work Day\",\n",
    "                \"weathersit_2\":\"Misty Weather\",\n",
    "                \"weathersit_3\":\"Light Precipitation\",\n",
    "                \"weathersit_4\":\"Heavy Precipitation\",\n",
    "                \"temp\":\"Temperature (F)\",\n",
    "                \"atemp\":\"Feels Like (F)\",\n",
    "                \"hum\":\"Humidity\",\n",
    "                \"windspeed\":\"Wind Speed\"\n",
    "            }\n",
    "            dataLoad = dataLoad.rename(mapper=feature_names_dict,axis=1) \n",
    "            features = feature_names_dict.values()\n",
    "\n",
    "            return {\n",
    "                \"x\": dataLoad[features].values,\n",
    "                \"y\": dataLoad[\"cnt\"],\n",
    "                \"feature_names\": features,\n",
    "                \"feature_locs\": {x:i for i,x in enumerate(features)},\n",
    "                \"target_type\": \"regression\"\n",
    "            }\n",
    "\n",
    "    def bin_data(self):\n",
    "    \n",
    "        prediction_contributions = {}\n",
    "        sample_data = pd.DataFrame(\n",
    "            self.get_sample(self.x),\n",
    "            columns = self.feature_names\n",
    "        )\n",
    "        for key in self.get_feature_pairs():\n",
    "            tempH = np.digitize(\n",
    "                sample_data.loc[:,key[0]],\n",
    "                self.feature_ranges[key[0]]\n",
    "            )-1.\n",
    "            tempV = np.digitize(\n",
    "                sample_data.loc[:,key[1]],\n",
    "                self.feature_ranges[key[1]]\n",
    "            )-1.\n",
    "            prediction_contributions[key] = (tempV*len(self.feature_ranges[key[0]]) + tempH).astype(int)\n",
    "        return prediction_contributions        \n",
    "        \n",
    "    def load_dataset(self, dataset):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        data = self.get_dataset(self.dataset)\n",
    "        self.x = data[\"x\"]\n",
    "        self.y = data[\"y\"]\n",
    "        self.feature_names = data[\"feature_names\"]\n",
    "        self.feature_locs = data[\"feature_locs\"]\n",
    "        self.target_type = data[\"target_type\"]\n",
    "        self.feature_ranges = {\n",
    "            feature : self.get_quantiles(feature)\n",
    "            for feature in self.feature_names\n",
    "        } \n",
    "        if self.sample_size is None:\n",
    "            self.sample_size = self.x.shape[0]\n",
    "        self.binned_data = self.bin_data()    \n",
    "            \n",
    "    def build_base_model(self, num_estimators):\n",
    "\n",
    "        self.model_type = \"regression\"\n",
    "        self.classifier_type = GradientBoostingRegressor\n",
    "\n",
    "        self.model = self.classifier_type(\n",
    "            n_estimators=num_estimators, \n",
    "            max_depth=2, \n",
    "            learning_rate = self.learning_rate\n",
    "        )\n",
    "        self.model.fit(self.x, self.y)\n",
    "        self.pred_y = self.model.predict(self.x)\n",
    "\n",
    "    def get_model_accuracy(self):\n",
    "        return r2_score(self.y, self.pred_y)    \n",
    "        \n",
    "    def _get_coordinate_matrix(self, lst, length, direction):\n",
    "        if direction==\"h\":\n",
    "            return lst*length\n",
    "        else:\n",
    "            return [item for item in lst\\\n",
    "             for i in range(length)]   \n",
    "\n",
    "    def get_quantile_matrix(self, feat1, feat2):\n",
    "        h = self._get_coordinate_matrix(\n",
    "            list(self.feature_ranges[feat1]),\n",
    "            len(self.feature_ranges[feat2]),\n",
    "            \"h\"\n",
    "        )\n",
    "        v = self._get_coordinate_matrix(\n",
    "            list(self.feature_ranges[feat2]),\n",
    "            len(self.feature_ranges[feat1]),\n",
    "            \"v\"\n",
    "        )                      \n",
    "        return h,v \n",
    "\n",
    "    def get_leaf_value(self, tree, node_position):\n",
    "        node = tree.value[node_position]\n",
    "        return node        \n",
    "\n",
    "    def get_feature_pair_key(self, feat1, feat2):\n",
    "        if self.feature_ranges[feat1].shape[0] == self.feature_ranges[feat2].shape[0]:\n",
    "            #need stable order so keys with same number of quantiles appear in only one order\n",
    "            return tuple(sorted([feat1, feat2]))\n",
    "        elif self.feature_ranges[feat1].shape[0] > self.feature_ranges[feat2].shape[0]:\n",
    "            return tuple([feat1, feat2])\n",
    "        else:\n",
    "            return tuple([feat2, feat1])        \n",
    "\n",
    "    def get_quantiles(self, feat):\n",
    "        loc = self.feature_locs[feat]\n",
    "        if np.unique(self.x[:,loc]).shape[0] < 30 or type(self.x[0,loc]) is str: #is categorical/ordinal?\n",
    "            return np.unique(self.x[:,loc])\n",
    "        else:\n",
    "            if self.quantiles:\n",
    "                return np.around(\n",
    "                    np.unique(\n",
    "                        np.quantile(\n",
    "                            a=self.x[:,loc],\n",
    "                            q=np.linspace(0, 1, self.num_tiles)\n",
    "                        )\n",
    "                    ),\n",
    "                    1)\n",
    "            else:\n",
    "                return np.around(\n",
    "                    np.linspace(\n",
    "                        np.min(self.x[:,loc]), \n",
    "                        np.max(self.x[:,loc]),\n",
    "                        self.num_tiles\n",
    "                    )\n",
    "                    ,1)  \n",
    "            \n",
    "    def reduce_to_1d(self, arr, threshold, direction):\n",
    "        if direction == \"h\":\n",
    "            reduced_arr = arr - arr[:,0].reshape(-1,1)\n",
    "        else:\n",
    "            reduced_arr = arr - arr[0,:].reshape(1,-1)\n",
    "        return (np.max(np.abs(reduced_arr))/np.max(np.abs(arr))) <= threshold               \n",
    "        \n",
    "    def get_sample(self, arr):\n",
    "        return arr[:self.sample_size]\n",
    "    \n",
    "    def get_predictions_base(self):\n",
    "        return np.full((self.sample_size,1), np.mean(self.y))\n",
    "    \n",
    "    def get_empty_sample(self, size = None):\n",
    "        return np.full((self.sample_size if size is None else size,1), 0)\n",
    "    \n",
    "    def get_explanation_accuracy(self, explanation_predictions):\n",
    "        return r2_score(self.get_sample(self.pred_y), explanation_predictions)\n",
    "        \n",
    "    def get_prediction_contributions(self, chart, data_positions):\n",
    "        return np.take(chart, data_positions)\n",
    "    \n",
    "    def sum_arrays(self, temp_outputs, keyMain, keyAdd, arr_to_add):\n",
    "        return temp_outputs[keyMain][\"output\"]\\\n",
    "    + temp_outputs[keyAdd][arr_to_add].reshape(\n",
    "            temp_outputs[keyMain][\"output\"].shape[0]\n",
    "            if(keyMain[1]==keyAdd[1] or keyMain[1]==keyAdd[0])\n",
    "            else 1,-1\n",
    "        )\n",
    "    \n",
    "    def _drop_alternate_outputs(self,component):\n",
    "        return {\"output\": component[\"output\"]}\n",
    "    \n",
    "    def _get_prediction_contributions_df(self, components, explanation):\n",
    "        return np.hstack(\n",
    "            tuple(\n",
    "                [\n",
    "                    self.get_prediction_contributions(\n",
    "                        components[expKey][\"output\"],\n",
    "                        self.binned_data[expKey]\n",
    "                    ).reshape(-1, 1)\\\n",
    "                    for expKey in explanation                    \n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def _get_prediction_contributions_by_key(self, components, explanation):\n",
    "        return {\n",
    "            expKey : \n",
    "            self.get_prediction_contributions(\n",
    "                components[expKey][\"output\"],\n",
    "                self.binned_data[expKey]\n",
    "            ) for expKey in explanation\n",
    "        }        \n",
    "\n",
    "    def evaluate_single_explanation(self, components, explanation):\n",
    "        \n",
    "        return self.get_explanation_accuracy(\n",
    "            self.predictions_base +\\\n",
    "            np.sum(\n",
    "                np.array(\n",
    "                    self._get_prediction_contributions_by_key(\n",
    "                        components,\n",
    "                        explanation\n",
    "                    ).values()\n",
    "                ), \n",
    "                axis = 0\n",
    "            ).reshape(-1,1)\n",
    "        )\n",
    "    \n",
    "    def _get_parallel_coordinate_columns(self, explanation, cumulative):\n",
    "        #make these strings because Altair doesn't like a tuple as a key and turns it into a list\n",
    "        return ([\"mean y\"] if cumulative else [])\\\n",
    "    + [x[0] + \",\" + x[1] for x in explanation]\\\n",
    "    + ([\"prediction\"] if cumulative else [])\n",
    "    \n",
    "    def _get_altair_data_type(self,feature_name, abbreviation = True):\n",
    "        if self.feature_ranges[feature_name].shape[0] == self.num_tiles:\n",
    "            return \"Q\" if abbreviation else \"quantitative\"\n",
    "        else:\n",
    "            return \"O\" if abbreviation else \"ordinal\"    \n",
    "    \n",
    "    def _get_datapoint_contributions(self, components, explanation):\n",
    "        contributions = self._get_prediction_contributions_df(components, explanation)\n",
    "        #raw contributions\n",
    "        arr = np.hstack(\n",
    "            (\n",
    "                self.get_empty_sample().reshape(-1,1),\n",
    "                contributions.reshape(self.sample_size, -1),\n",
    "                self.get_sample(self.pred_y).reshape(-1,1),\n",
    "                np.array([0. for x in range(self.sample_size)]).reshape(-1,1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        #cumulative version\n",
    "        arr_cum = np.cumsum(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    self.get_predictions_base().reshape(-1,1),\n",
    "                    contributions.reshape(self.sample_size,-1)\n",
    "                )\n",
    "            ),\n",
    "            axis = 1\n",
    "        )\n",
    "        \n",
    "        arr_cum = np.hstack(\n",
    "            (\n",
    "                arr_cum,\n",
    "                self.get_sample(self.pred_y).reshape(-1,1),\n",
    "                np.array([1. for x in range(self.sample_size)]).reshape(-1,1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        arr_df = pd.DataFrame(\n",
    "            arr,\n",
    "            columns = self._get_parallel_coordinate_columns(explanation, True) + [\"view\"]\n",
    "        )\n",
    "        \n",
    "        #combine arrays\n",
    "        arr_cum_df = pd.DataFrame(\n",
    "            arr_cum,\n",
    "            columns = self._get_parallel_coordinate_columns(explanation, True) + [\"view\"]\n",
    "        )\n",
    "        \n",
    "        #generate datapoint id columns\n",
    "        arr_df = arr_df.reset_index(drop = False)\n",
    "        arr_cum_df = arr_cum_df.reset_index(drop = False)\n",
    "        datapoints = pd.concat([arr_df, arr_cum_df])\n",
    "        \n",
    "        #couldn't do this earlier, as you can't vstack a mixed type array\n",
    "        datapoints[\"view\"] = datapoints[\"view\"].apply(lambda x:\\\n",
    "                                                      'Predictions by Chart'\\\n",
    "                                                      if x < 1. else\\\n",
    "                                                      'Cumulative Predictions'\\\n",
    "                                                     )\n",
    "        #calculate explanation loss\n",
    "        datapoints[\"explanation_loss\"] = np.abs( #otherwise the chart is hard to read with 0 in the middle of the axis\n",
    "            datapoints.loc[:,\"prediction\"] - datapoints.iloc[:,-3]#last cumulative column\n",
    "        )\n",
    "        \n",
    "        #datapoints = datapoints.reset_index(drop = False)\n",
    "        datapoints[\"prediction_index\"] = datapoints[\"prediction\"]\n",
    "        datapoints = datapoints.melt(\n",
    "            id_vars = ['index', \"prediction_index\", \"view\", \"explanation_loss\"],\n",
    "            var_name = 'component',\n",
    "            value_name = 'contribution'\n",
    "        )\n",
    "        \n",
    "        #rename prediction again\n",
    "        datapoints = datapoints.rename({\"prediction_index\" : \"prediction\"}, axis = 1)\n",
    "\n",
    "        #drop fake columns for \"Predictions by Chart\"\n",
    "        datapoints = datapoints[\n",
    "            (datapoints[\"view\"] == \"Cumulative Predictions\")\n",
    "            | (~datapoints[\"component\"].isin([\"prediction\", \"mean y\", \"explanation_loss\"]))\n",
    "        ]\n",
    "        \n",
    "        #build sort column for Altair\n",
    "        datapoints[\"sort\"] = datapoints[\"component\"].apply(lambda x:\n",
    "                                                           self._get_parallel_coordinate_columns(\n",
    "                                                               explanation,\n",
    "                                                               True\n",
    "                                                           ).index(x)\n",
    "                                                          )   \n",
    "        return datapoints\n",
    "\n",
    "    def copy_chart_components(self):\n",
    "        return copy.deepcopy(self.chart_components)  \n",
    "    \n",
    "    def get_feature_pairs(self):\n",
    "        return [\n",
    "            self.get_feature_pair_key(key[0], key[1])\n",
    "            for key in [tuple(t) for t in product(self.feature_names, repeat = 2)]\n",
    "        ]       \n",
    "\n",
    "    def rollup_components(self, explanation):\n",
    "        temp_outputs = self.copy_chart_components()\n",
    "        for keyRollup in [k for k in self.chart_components.iterkeys() if k not in explanation]:\n",
    "            hUsed = False\n",
    "            vUsed = False\n",
    "            for keyExisting in explanation:\n",
    "                if (keyRollup[1] == keyExisting[0] or keyRollup[1] == keyExisting[1]) and not hUsed:\n",
    "                    hUsed = True\n",
    "                    if vUsed:\n",
    "                        temp_outputs[keyExisting][\"output\"] = self.sum_arrays(\n",
    "                            temp_outputs,\n",
    "                            keyExisting, \n",
    "                            keyRollup,\n",
    "                            \"output_HReduced\"\n",
    "                        )\n",
    "                        break\n",
    "                    else:\n",
    "                        temp_outputs[keyExisting][\"output\"] = self.sum_arrays(\n",
    "                            temp_outputs,\n",
    "                            keyExisting, \n",
    "                            keyRollup,\n",
    "                            \"output_H\"\n",
    "                        )                           \n",
    "                elif (keyRollup[0] == keyExisting[0] or keyRollup[0] == keyExisting[1]) and not vUsed:\n",
    "                    vUsed = True\n",
    "                    if hUsed:\n",
    "                        temp_outputs[keyExisting][\"output\"] = self.sum_arrays(\n",
    "                            temp_outputs,\n",
    "                            keyExisting, \n",
    "                            keyRollup,\n",
    "                            \"output_VReduced\"\n",
    "                        )                          \n",
    "                        break\n",
    "                    else:\n",
    "                        temp_outputs[keyExisting][\"output\"] = self.sum_arrays(\n",
    "                            temp_outputs,\n",
    "                            keyExisting, \n",
    "                            keyRollup,\n",
    "                            \"output_V\"\n",
    "                        )  \n",
    "        return temp_outputs   \n",
    "    \n",
    "    def visualize_single_estimator(self, estimator_num):\n",
    "        \n",
    "        chart_components,\\\n",
    "        chart_indices,\\\n",
    "        _,\\\n",
    "        _ = self._extract_components(False, [self.model.estimators_[estimator_num]])\n",
    "        \n",
    "        chart = self._visualize_components(\n",
    "            [chart_components.keys()[0]],\n",
    "            chart_components,\n",
    "            None,\n",
    "            chart_indices,\n",
    "            False, \n",
    "            300\n",
    "        )\n",
    "        display(chart)\n",
    "        return chart\n",
    "    \n",
    "    def extract_components(self, collapse_1d = True):\n",
    "        \n",
    "        self.chart_components,\\\n",
    "        self.chart_indices,\\\n",
    "        self.no_predictor_features,\\\n",
    "        self.oned_features = self._extract_components(collapse_1d, self.model.estimators_)\n",
    "        \n",
    "        self.predictions_base = self.get_predictions_base()\n",
    "        \n",
    "        #get the full explanation and store it. one reason for this is so that\n",
    "        #charts can also be sorted appropriately\n",
    "        #don't save explanation components as they will be the same as chart_components\n",
    "        self.base_explanation, _, _\\\n",
    "        = self._explain(1., None)        \n",
    "        \n",
    "    def _extract_components(self, collapse_1d, estimators):\n",
    "\n",
    "        #generate data structure for pairwise charts\n",
    "        feature_pairs = {\n",
    "            key : {\n",
    "                \"map\":None,\n",
    "                \"predicates\":[]\n",
    "            }\n",
    "            for key in self.get_feature_pairs()\n",
    "        }      \n",
    "\n",
    "        for key, value in feature_pairs.iteritems():\n",
    "            h, v = self.get_quantile_matrix(key[0], key[1])\n",
    "            value[\"map\"] = np.array(\n",
    "                [\n",
    "                    {\n",
    "                        key[0] : x,\n",
    "                        key[1] : y\n",
    "                    }\n",
    "                    for x,y in zip(h,v)\n",
    "                ]\n",
    "            ).reshape(len(self.feature_ranges[key[1]]), len(self.feature_ranges[key[0]]))\n",
    "\n",
    "        for modelT in estimators:\n",
    "            curr_model = modelT[0]\n",
    "            feature_ids = {\n",
    "                i : {\n",
    "                    \"number\":x,\n",
    "                    \"name\":self.feature_names[x]\n",
    "                } for i,x in enumerate(list(curr_model.tree_.feature))\n",
    "                if x >= 0\n",
    "            } #-2 means leaf node\n",
    "\n",
    "            #for 1-layer trees\n",
    "            if curr_model.tree_.feature[1] < 0:\n",
    "                feature_pair_key = self.get_feature_pair_key(\n",
    "                    feature_ids[0][\"name\"],\n",
    "                    feature_ids[0][\"name\"]\n",
    "                )\n",
    "                decision_func_dict = {\n",
    "                    \"feature_name\": feature_ids[0][\"name\"],\n",
    "                    \"threshold\": curr_model.tree_.threshold[0],\n",
    "                    \"operator\": operator.le,\n",
    "                    \"prob_le\": self.get_leaf_value(curr_model.tree_, 1),\n",
    "                    \"prob_gt\": self.get_leaf_value(curr_model.tree_, 2)\n",
    "                }       \n",
    "                #build the predictive function used in the decision tree\n",
    "                def dt_predicate(data_case, decision_func_dict=decision_func_dict):\n",
    "                    if decision_func_dict[\"operator\"](\\\n",
    "                                                        data_case[decision_func_dict[\"feature_name\"]],\\\n",
    "                                                        decision_func_dict[\"threshold\"]\\\n",
    "                                                       ):\n",
    "                        return decision_func_dict[\"prob_le\"]\n",
    "                    else:\n",
    "                        return decision_func_dict[\"prob_gt\"]        \n",
    "            else:\n",
    "                for node_position in [1,4]: #positions for left and right nodes at layer 2\n",
    "                    if node_position in feature_ids:\n",
    "                        feature_pair_key = self.get_feature_pair_key(\n",
    "                            feature_ids[0][\"name\"], \n",
    "                            feature_ids[node_position][\"name\"]\n",
    "                        )\n",
    "                        #get the decision rules\n",
    "                        decision_func_dict = {\n",
    "                            \"feature_name_1\": feature_ids[0][\"name\"],\n",
    "                            \"threshold_1\": curr_model.tree_.threshold[0],\n",
    "                            \"operator_1\": operator.le if node_position == 1 else operator.gt,\n",
    "\n",
    "                            \"feature_name_2\": feature_ids[node_position][\"name\"],\n",
    "                            \"threshold_2\": curr_model.tree_.threshold[node_position],\n",
    "                            \"operator_2\": operator.le,\n",
    "\n",
    "                            \"prob_le\": self.get_leaf_value(curr_model.tree_, node_position+1),\n",
    "                            \"prob_gt\": self.get_leaf_value(curr_model.tree_, node_position+2)\n",
    "                        }\n",
    "                        #build the predictive function used in the decision tree\n",
    "                        def dt_predicate(data_case, decision_func_dict=decision_func_dict):\n",
    "                            if decision_func_dict[\"operator_1\"](\\\n",
    "                                                                data_case[decision_func_dict[\"feature_name_1\"]],\\\n",
    "                                                                decision_func_dict[\"threshold_1\"]\\\n",
    "                                                               ):\n",
    "                                if decision_func_dict[\"operator_2\"](\\\n",
    "                                                                    data_case[decision_func_dict[\"feature_name_2\"]],\\\n",
    "                                                                    decision_func_dict[\"threshold_2\"]\\\n",
    "                                                                   ):\n",
    "                                    return decision_func_dict[\"prob_le\"]\n",
    "                                else:\n",
    "                                    return decision_func_dict[\"prob_gt\"]\n",
    "                            else:\n",
    "                                return 0.\n",
    "\n",
    "                    else: #asymmetric tree, this is a leaf node\n",
    "                        feature_pair_key = self.get_feature_pair_key(\n",
    "                            feature_ids[0][\"name\"], \n",
    "                            feature_ids[0][\"name\"]\n",
    "                        )\n",
    "                        decision_func_dict = {\n",
    "                            \"feature_name\": feature_ids[0][\"name\"],\n",
    "                            \"threshold\": curr_model.tree_.threshold[0],\n",
    "                            \"operator\": operator.le if node_position == 1 else operator.gt,\n",
    "                            \"prob\": curr_model.tree_.value[node_position]\n",
    "                        }\n",
    "                        #build the predictive function used in the decision tree\n",
    "                        def dt_predicate(data_case, decision_func_dict=decision_func_dict):\n",
    "                            if decision_func_dict[\"operator\"](\\\n",
    "                                                                data_case[decision_func_dict[\"feature_name\"]],\\\n",
    "                                                                decision_func_dict[\"threshold\"]\\\n",
    "                                                               ):\n",
    "                                return decision_func_dict[\"prob\"]\n",
    "                            else:                         \n",
    "                                return 0.                 \n",
    "\n",
    "                    feature_pairs[feature_pair_key][\"predicates\"].append(dt_predicate)\n",
    "                    if return_texts:\n",
    "                        feature_pairs[feature_pair_key][\"function_text\"].append(\n",
    "                            _get_function_text(\n",
    "                                dt_predicate\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "        #now calculate output array for each feature pair\n",
    "        for key, value in feature_pairs.iteritems():\n",
    "            arrs = []\n",
    "            for predicate in value[\"predicates\"]:\n",
    "                f = np.vectorize(predicate)\n",
    "                arrs.append(f(value[\"map\"]))\n",
    "            if len(arrs) > 0:\n",
    "                #details of vote aggreggation method for random forest\n",
    "                #https://stats.stackexchange.com/questions/127077/random-forest-probabilistic-prediction-vs-majority-vote\n",
    "                value[\"output\"] = np.sum(np.stack(arrs, axis=-1), axis=-1)*self.learning_rate \n",
    "            else:\n",
    "                value[\"output\"] = None\n",
    "\n",
    "        #build chart data\n",
    "        for key, value in feature_pairs.iteritems():\n",
    "            h,v = self.get_quantile_matrix(key[0], key[1])\n",
    "            value[\"h_indices\"] = h\n",
    "            value[\"v_indices\"] = v    \n",
    "\n",
    "        no_predictor_features = []\n",
    "        oned_features = []\n",
    "        chart_data = {}\n",
    "        for key, value in feature_pairs.iteritems(): \n",
    "            newKey = key\n",
    "            if value[\"output\"] is None:\n",
    "                no_predictor_features.append(key)\n",
    "                value[\"removed\"] = True\n",
    "            else:          \n",
    "                if collapse_1d:\n",
    "                    if self.reduce_to_1d(value[\"output\"], 0., \"v\"):\n",
    "                        newKey = key[1]\n",
    "                        value[\"output\"] = value[\"output\"][0,:]\n",
    "                        value[\"h_indices\"] = self.feature_ranges[newKey]\n",
    "                        value[\"v_indices\"] = None\n",
    "                        value[\"1d_key\"] = newKey\n",
    "                        value[\"removed\"] = True\n",
    "                        oned_features.append(key)                 \n",
    "                    elif self.reduce_to_1d(value[\"output\"], 0., \"h\"):\n",
    "                        newKey = key[0]\n",
    "                        value[\"output\"] = value[\"output\"][:,0]\n",
    "                        value[\"h_indices\"] = self.feature_ranges[newKey]\n",
    "                        value[\"v_indices\"] = None\n",
    "                        value[\"1d_key\"] = newKey\n",
    "                        value[\"removed\"] = True\n",
    "                        oned_features.append(key)\n",
    "\n",
    "        #do another loop through chart_data to push 1d charts into 2d\n",
    "        if collapse_1d:\n",
    "            for value in feature_pairs.itervalues():\n",
    "                if value[\"v_indices\"] is None:\n",
    "                    key = value[\"1d_key\"]\n",
    "                    #get list of charts with this feature\n",
    "                    matchList = sorted([{\"key\": kInner, \"feature_importance\": np.std(vInner[\"output\"])}\\\n",
    "                                        for kInner, vInner in feature_pairs.iteritems()\\\n",
    "                                        if \"removed\" not in vInner and key in kInner],\\\n",
    "                                       key=lambda x: x[\"feature_importance\"], reverse=True)\n",
    "\n",
    "                    if len(matchList) > 0:\n",
    "                        matchKey = matchList[0][\"key\"]\n",
    "                        feature_pairs[matchKey][\"output\"] = feature_pairs[matchKey][\"output\"]\\\n",
    "                        + value[\"output\"].reshape(\\\n",
    "                                                  -1 if key == matchKey[1] else 1,\\\n",
    "                                                  -1 if key == matchKey[0] else 1\\\n",
    "                                                 )\n",
    "\n",
    "        #one last loop to generate the horizontal and vertical components\n",
    "        for key, value in feature_pairs.iteritems():\n",
    "            if \"removed\" in value:\n",
    "                pass\n",
    "            else:\n",
    "                value[\"output_H\"] = np.mean(value[\"output\"], axis=1).reshape(-1,1)\n",
    "                value[\"output_V\"] = np.mean(value[\"output\"], axis=0).reshape(1,-1)\n",
    "                value[\"output_HReduced\"] = np.mean(value[\"output\"] - value[\"output_V\"].reshape(1,-1), axis=1)\\\n",
    "                .reshape(1,-1)\n",
    "                value[\"output_VReduced\"] = np.mean(value[\"output\"] - value[\"output_H\"].reshape(-1,1), axis=0)\\\n",
    "                .reshape(-1,1)\n",
    "\n",
    "        #remove deleted keys\n",
    "        feature_pairs = {key:val for key, val in feature_pairs.iteritems() if \"removed\" not in val}\n",
    "        feature_pairs = OrderedDict(sorted(feature_pairs.items(),\\\n",
    "                                            key=lambda x: np.std(x[1][\"output\"]), reverse=True))\n",
    "        chart_components = {\n",
    "            key: {\n",
    "                \"output\" : val[\"output\"],\n",
    "                \"output_VReduced\" : val[\"output_VReduced\"],\n",
    "                \"output_H\" : val[\"output_H\"],\n",
    "                \"output_HReduced\" : val[\"output_HReduced\"],\n",
    "                \"output_V\" : val[\"output_V\"]\n",
    "            } for key, val in feature_pairs.iteritems()\n",
    "        }\n",
    "\n",
    "        chart_indices = {\n",
    "            key: {\n",
    "                \"h_indices\" : val[\"h_indices\"],\n",
    "                \"v_indices\" : val[\"v_indices\"]\n",
    "            } for key, val in feature_pairs.iteritems()\n",
    "        }\n",
    "        \n",
    "        function_texts = {\n",
    "            key : {\n",
    "                \"function_text\" : val[\"function_text\"]\n",
    "            } for key, val in feature_pairs.iteritems()\n",
    "        } if return_texts else None\n",
    "        \n",
    "        return chart_components, chart_indices, no_predictor_features, oned_features, function_texts\n",
    "        \n",
    "    def _explain(self, fidelity_threshold = 1., rollup = None):\n",
    "\n",
    "        explanation = []   \n",
    "        explanation_components = {}\n",
    "        evaluation_details = [\n",
    "            {\n",
    "                \"score\": self.get_explanation_accuracy(\n",
    "                    self.predictions_base\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        while evaluation_details[-1][\"score\"] < fidelity_threshold\\\n",
    "        and len(explanation) < len(self.chart_components):\n",
    "            current_details = {}\n",
    "            temp_outputs = {}\n",
    "            keys_to_evaluate = [key for key in self.chart_components.iterkeys() if key not in explanation]\n",
    "            for key in keys_to_evaluate:\n",
    "                #roll up other keys\n",
    "                current_explanation = explanation+[key]\n",
    "                temp_outputs[key] = self.rollup_components(current_explanation)\\\n",
    "                if rollup == \"advanced\"\\\n",
    "                else self.copy_chart_components()\n",
    "\n",
    "                current_details[key] = self.evaluate_single_explanation(temp_outputs[key], current_explanation)\n",
    "\n",
    "            #get key with highest fidelity score\n",
    "            best_key = max(\n",
    "                current_details.iterkeys(),\\\n",
    "                key = (lambda key: current_details[key])\n",
    "            )\n",
    "            explanation.append(best_key)\n",
    "            current_details[\"best_key\"] = best_key\n",
    "\n",
    "            if rollup == \"simple\":\n",
    "                temp_outputs[best_key] = self.rollup_components(explanation)\n",
    "                current_details[best_key] = self.evaluate_single_explanation(temp_outputs[best_key], explanation)\n",
    "\n",
    "            \n",
    "            current_details[\"score\"] = current_details[best_key]\n",
    "            evaluation_details.append(current_details)\n",
    "            explanation_components = {k : self._drop_alternate_outputs(v)\\\n",
    "                                      for k, v in temp_outputs[best_key].iteritems()}\n",
    "        return explanation, explanation_components, evaluation_details\n",
    "    \n",
    "    def explain(self, fidelity_threshold = 1., rollup = None):\n",
    "        self.explanation, self.explanation_components, self.evaluation_details\\\n",
    "        = self._explain(fidelity_threshold, rollup)\n",
    "        \n",
    "    def cache_visualize_components(self, start = 1, end = 100, step = 1):\n",
    "        self.cache[\"play_components\"] = []\n",
    "        for i in range(start, end+1, step):\n",
    "            ft = ForestForTheTrees(\n",
    "                dataset = self.dataset,\n",
    "                sample_size = self.sample_size,\n",
    "                num_tiles = self.num_tiles,\n",
    "                quantiles = self.quantiles,\n",
    "                learning_rate = self.learning_rate\n",
    "            )\n",
    "            ft.build_base_model(i)\n",
    "            ft.extract_components(True)\n",
    "            self.cache[\"play_components\"].append(\n",
    "                {\n",
    "                    \"explanation\" : ft.base_explanation,\n",
    "                    \"components\" : ft.chart_components,\n",
    "                    \"chart_indices\" : ft.chart_indices\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    def cache_visualize_datapoints(self):\n",
    "        \n",
    "        minimal = self._get_datapoint_contributions(\n",
    "            self.explanation_components,\n",
    "            self.explanation\n",
    "        )\n",
    "        \n",
    "        full = self._get_datapoint_contributions(\n",
    "            self.explanation_components,\n",
    "            self.base_explanation\n",
    "        )\n",
    "        \n",
    "        minimal[\"explanation\"] = \"minimal\"\n",
    "        full[\"explanation\"] = \"full\"\n",
    "        \n",
    "        self.cache[\"datapoints\"] = pd.concat([minimal, full])\n",
    "        \n",
    "    def visualize_datapoints(self, cumulative = False, num_datapoints = 50, explanation_type = \"minimal\",\n",
    "                            color_encoding = \"prediction\"):\n",
    "        output = self._visualize_datapoints(explanation_type, cumulative, num_datapoints, color_encoding)\n",
    "        display(output)\n",
    "        return output\n",
    "    \n",
    "    def _visualize_datapoints(self, explanation_type, cumulative, num_datapoints, color_encoding):\n",
    "        \n",
    "        explanation_to_visualize = self.explanation\\\n",
    "        if len(self.explanation) > 0 and explanation_type == \"minimal\"\\\n",
    "        else self.base_explanation        \n",
    "        \n",
    "        if \"datapoints\" in self.cache and self.cache[\"datapoints\"] is not None:\n",
    "            datapoints = self.cache[\"datapoints\"]\n",
    "            datapoints = datapoints[datapoints[\"explanation\"] == explanation_type]\n",
    "        \n",
    "        else:            \n",
    "            datapoints = self._get_datapoint_contributions(\n",
    "                self.explanation_components,\n",
    "                explanation_to_visualize\n",
    "            )\n",
    "        \n",
    "        unique_datapoint_ids = np.unique(datapoints.loc[:,\"index\"])\n",
    "        sample_datapoint_ids = np.random.choice(unique_datapoint_ids, num_datapoints, replace = False)\n",
    "        datapoints = datapoints[datapoints[\"index\"].isin(sample_datapoint_ids)]\n",
    "        datapoints = datapoints[datapoints[\"view\"] == (\"Cumulative Predictions\"\\\n",
    "                                                       if cumulative\\\n",
    "                                                       else \"Predictions by Chart\")\n",
    "                               ]\n",
    "        \n",
    "        df_raw = pd.DataFrame(self.x, columns = self.feature_names)\n",
    "        df_raw[\"prediction\"] = self.pred_y\n",
    "        df_raw = df_raw.reset_index(drop = False)\n",
    "        df_raw = df_raw[df_raw[\"index\"].isin(sample_datapoint_ids)]       \n",
    "        \n",
    "        brush = alt.selection_multi()\n",
    "        chart = alt.Chart(data = datapoints)\\\n",
    "        .mark_line()\\\n",
    "        .encode(\n",
    "            x = alt.X(\n",
    "                field = 'component',\n",
    "                type = 'nominal',\n",
    "                axis = alt.Axis(labelAngle = -30),\n",
    "                sort = self._get_parallel_coordinate_columns(explanation_to_visualize, cumulative)\n",
    "            ),\n",
    "            y ='contribution:Q',\n",
    "            color = alt.condition(\n",
    "                brush,\n",
    "                alt.Color(\n",
    "                    field = color_encoding,\n",
    "                    type = \"quantitative\",\n",
    "                    scale = alt.Scale(scheme = \"plasma\")\n",
    "                ),\n",
    "                alt.value(\"lightgray\")\n",
    "            ),\n",
    "            opacity = alt.condition(\n",
    "                brush,\n",
    "                alt.value(1.0),\n",
    "                alt.value(0.2)\n",
    "            ),\n",
    "            tooltip = [\n",
    "                alt.Tooltip(x+\":\"+self._get_altair_data_type(x))\n",
    "                for x in self.feature_names\n",
    "            ] + [\n",
    "                alt.Tooltip(x+\":Q\")\n",
    "                for x in [\"prediction\", \"explanation_loss\"]                \n",
    "            ],         \n",
    "            detail = 'index:N',\n",
    "            order = \"sort:N\"\n",
    "        ).transform_lookup(\n",
    "            lookup = 'index',\n",
    "            from_ = alt.LookupData(\n",
    "                data = df_raw, \n",
    "                key = 'index',\n",
    "                fields = self.feature_names\n",
    "            )\n",
    "        ).properties(\n",
    "            height = 300,\n",
    "            width = 800\n",
    "        ).add_selection(\n",
    "            brush\n",
    "        )\n",
    "        \n",
    "        return chart\n",
    "        \n",
    "    def visualize_components(self, plot_points = True, chart_size = 150):\n",
    "        if len(self.explanation) > 0:\n",
    "            explanation_to_visualize = self.explanation\n",
    "            components = self.explanation_components\n",
    "        else:\n",
    "            explanation_to_visualize = self.base_explanation\n",
    "            components = self.chart_components\n",
    "        return self._visualize_components(\n",
    "            explanation_to_visualize,\n",
    "            components,\n",
    "            None,\n",
    "            self.chart_indices,\n",
    "            plot_points,\n",
    "            chart_size\n",
    "        )\n",
    "    \n",
    "    def play_components(self, cache_id):\n",
    "        output = self._visualize_components(\n",
    "            #-1 deals with the fact that list is zero-based but number of trees starts at 1\n",
    "            self.cache[\"play_components\"][cache_id-1][\"explanation\"],\n",
    "            self.cache[\"play_components\"][cache_id-1][\"components\"],\n",
    "            self.cache[\"play_components\"][cache_id-2][\"components\"] if cache_id > 1 else None,\n",
    "            self.cache[\"play_components\"][cache_id-1][\"chart_indices\"],\n",
    "            False,\n",
    "            150\n",
    "        )\n",
    "        display(output)\n",
    "        return output\n",
    "        \n",
    "    def _visualize_components(self, explanation, components, ref_components, chart_indices,\n",
    "                              plot_points, chart_size):\n",
    "        i = 1\n",
    "        rows = []\n",
    "        charts = []\n",
    "        self.temp_components = components.copy()\n",
    "        self.temp_indices = chart_indices.copy()\n",
    "        for key in explanation:\n",
    "            \n",
    "            chart_df = pd.DataFrame(\n",
    "                np.hstack(\n",
    "                    (\n",
    "                        np.array(chart_indices[key][\"h_indices\"]).reshape(-1,1),\n",
    "                        np.array(chart_indices[key][\"v_indices\"]).reshape(-1,1),\n",
    "                        components[key][\"output\"].ravel().reshape(-1,1),\n",
    "                        \n",
    "                        ref_components[key][\"output\"].ravel().reshape(-1,1)\\\n",
    "                        if ref_components is not None and key in ref_components\\\n",
    "                        else self.get_empty_sample(len(chart_indices[key][\"h_indices\"])).reshape(-1,1)\n",
    "                    )\n",
    "                ),\n",
    "                columns = [\"h_indices\", \"v_indices\", \"contributions\", \"ref_contributions\"]\n",
    "            )\n",
    "            \n",
    "            #figure out cells that should be highlighted\n",
    "            chart_df[\"is_changed\"]\\\n",
    "            = chart_df.apply(lambda x:\n",
    "                             abs(x[\"ref_contributions\"] - x[\"contributions\"])/abs(x[\"contributions\"]+0.001) > 0.05\\\n",
    "                             or (x[\"contributions\"] != 0. and key not in ref_components)#new chart this step\n",
    "                             if ref_components is not None else False,\n",
    "                             axis = 1\n",
    "                            )\n",
    "\n",
    "            y_encoding = alt.Y(\n",
    "                field = \"v_indices\",\n",
    "                type = \"ordinal\",\n",
    "                sort = \"descending\",\n",
    "                axis = alt.Axis(title = key[1])\n",
    "            )                \n",
    "\n",
    "            x_encoding = alt.X(\n",
    "                field = \"h_indices\",\n",
    "                type = \"ordinal\",\n",
    "                sort = \"ascending\",\n",
    "                axis = alt.Axis(\n",
    "                    title = key[0],\n",
    "                    labelAngle = 0,\n",
    "                    labelOverlap = \"greedy\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            color_encoding = alt.Color(\n",
    "                field = \"contributions\",\n",
    "                type = \"quantitative\",\n",
    "                scale = alt.Scale(\n",
    "                    scheme = \"redblue\",\n",
    "                    domain = [\n",
    "                        np.min([np.min(x[\"output\"]) for x in self.explanation_components.values()]),\n",
    "                        np.max([np.max(x[\"output\"]) for x in self.explanation_components.values()])\n",
    "                    ]\n",
    "                ),\n",
    "                legend = alt.Legend(title = \"Votes\")\n",
    "            )\n",
    "            \n",
    "            tooltip_encoding = [\n",
    "                alt.Tooltip('h_indices:O', title = key[0]),\n",
    "                alt.Tooltip('v_indices:O', title = key[1]),\n",
    "                alt.Tooltip(\"contributions:Q\", title = \"Contribution\")\n",
    "            ]\n",
    "\n",
    "            chart = alt.Chart(data = chart_df).mark_rect()\n",
    "\n",
    "            chart = chart.encode(\n",
    "                x = x_encoding, \n",
    "                y = y_encoding, \n",
    "                color = color_encoding,\n",
    "                tooltip = tooltip_encoding\n",
    "            ).properties(width = chart_size, height = chart_size)\n",
    "\n",
    "            if plot_points:\n",
    "                point_df = pd.DataFrame(self.x[np.random.choice(self.x.shape[0],500,replace = False),:],\\\n",
    "                                  columns = self.feature_names)\n",
    "                points = alt.Chart(point_df).mark_circle(\n",
    "                    color = 'black',\n",
    "                    size = 2\n",
    "                ).encode(\n",
    "                    x = alt.X(field = key[0], type = \"quantitative\", sort = \"ascending\", axis = None),\n",
    "                    y = alt.Y(field = key[1], type = \"quantitative\", sort = \"ascending\", axis = None)\n",
    "                ).properties(width = chart_size, height = chart_size)\n",
    "                chart = chart + points\n",
    "                #chart = chart.resolve_scale(x = \"independent\", y = \"independent\")\n",
    "                \n",
    "            elif ref_components is not None:\n",
    "                changes = alt.Chart(data = chart_df[chart_df[\"is_changed\"]]).mark_circle(size = 8).encode(\n",
    "                    x = alt.X(field = \"h_indices\", type = \"ordinal\", sort = \"ascending\", axis = None),\n",
    "                    y = alt.Y(field = \"v_indices\", type = \"ordinal\", sort = \"descending\", axis = None)\n",
    "                ).properties(width = chart_size, height = chart_size)\n",
    "                chart = chart + changes\n",
    "                chart = chart.resolve_scale(y = \"independent\")\n",
    "\n",
    "            charts.append(chart)\n",
    "            if len(charts) == 4 or i == len(explanation):\n",
    "                rows.append(alt.hconcat(*charts))\n",
    "                charts = []\n",
    "            i += 1\n",
    "        return alt.vconcat(*rows)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2t = ForestForTheTrees(dataset = \"bike\", sample_size = None, num_tiles = 20, quantiles = False, learning_rate = 1.)\n",
    "f2t.build_base_model(300)\n",
    "f2t.extract_components(True)\n",
    "f2t.explain(.95, None)\n",
    "#f2t.visualize(True, 100)\n",
    "#f2t.cache_visualize_datapoints()\n",
    "#f2t.cache_visualize_components(start = 1, end = 10, step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2t.visualize_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_estimator_slider = wid.IntSlider(\n",
    "    value = 1,\n",
    "    min = 1,\n",
    "    max = 300,\n",
    "    step = 1,\n",
    "    continuous_update = False,\n",
    "    description = \"Tree #\"\n",
    ")\n",
    "ui = wid.HBox([single_estimator_slider])\n",
    "output = wid.interactive_output(\n",
    "    f2t.visualize_single_estimator,\n",
    "    {\"estimator_num\" : single_estimator_slider}\n",
    ")\n",
    "display(ui, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_control = wid.Play(\n",
    "    interval = 3000,\n",
    "    value = 1,\n",
    "    min = 1,\n",
    "    max = 10,\n",
    "    step = 1,\n",
    "    description = \"Press play\"\n",
    ")\n",
    "play_slider = wid.IntSlider(\n",
    "    value = 1,\n",
    "    min = 1,\n",
    "    max = 10,\n",
    "    step = 1,\n",
    "    continuous_update = False,\n",
    "    description = \"# of trees\"\n",
    ")\n",
    "wid.jslink((play_control, 'value'), (play_slider, 'value'))\n",
    "ui = wid.HBox([play_control, play_slider])\n",
    "output = wid.interactive_output(\n",
    "    f2t.play_components,\n",
    "    {\"cache_id\" : play_control}\n",
    ")\n",
    "display(ui, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f2t.cache_visualize_datapoints()\n",
    "cumulative_selector = wid.Dropdown(\n",
    "    options = [('Cumulative Prediction', True), ('Contributions by Feature', False)],\n",
    "    value = True,\n",
    "    description = 'View',\n",
    ")\n",
    "\n",
    "num_datapoints_slider = wid.IntSlider(\n",
    "    value = 50,\n",
    "    min = 1,\n",
    "    max = 500,\n",
    "    step = 5,\n",
    "    description = '# datapoints',\n",
    "    continuous_update = False,\n",
    "    orientation = 'horizontal',\n",
    "    readout = True,\n",
    "    readout_format = 'd'\n",
    ")\n",
    "\n",
    "explanation_selector = wid.Dropdown(\n",
    "    options = [('95%',\"minimal\"), ('Full', \"full\")],\n",
    "    value = \"minimal\",\n",
    "    description = 'Explanation',\n",
    ")\n",
    "\n",
    "color_encoding_selector = wid.Dropdown(\n",
    "    options = f2t.feature_names + [\"prediction\", \"explanation_loss\"],\n",
    "    value = \"prediction\",\n",
    "    description = 'Color By',\n",
    ")\n",
    "\n",
    "ui = wid.HBox([cumulative_selector, explanation_selector, color_encoding_selector, num_datapoints_slider])\n",
    "\n",
    "output = wid.interactive_output(\n",
    "    f2t.visualize_datapoints,\n",
    "    {\n",
    "        \"cumulative\" : cumulative_selector,\n",
    "        \"num_datapoints\" : num_datapoints_slider,\n",
    "        \"explanation_type\" : explanation_selector,\n",
    "        \"color_encoding\" : color_encoding_selector\n",
    "    }\n",
    ")\n",
    "\n",
    "display(ui, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.DataFrame(pd.DataFrame(np.abs(f2t.y-f2t.pred_y))).iloc[:4999,:])\\\n",
    ".transform_window(\n",
    "    sort=[{'field': 'cnt'}],\n",
    "    frame=[None, 0],\n",
    "    cumulative_count='count(*)',\n",
    ")\\\n",
    ".mark_rect().encode(\n",
    "    x = alt.X(\"cnt\", bin = alt.Bin(maxbins = 20)),\n",
    "    y = \"cumulative_count:Q\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataset = f2t.get_dataset(\"bike\")\n",
    "effect_additional_trees = []\n",
    "train_x, test_x, train_y, test_y\\\n",
    "= train_test_split(bike_dataset[\"x\"], bike_dataset[\"y\"], test_size = 0.3)\n",
    "for estimators in range(5, 300, 10):\n",
    "    for depth in range(1,5):\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators = estimators, \n",
    "            max_depth = depth, \n",
    "            learning_rate = 1\n",
    "        )\n",
    "        model.fit(train_x, train_y)\n",
    "        effect_additional_trees.append(\n",
    "            {\n",
    "                \"number of trees\" : estimators,\n",
    "                \"depth\" : depth, \n",
    "                \"train\" : r2_score(model.predict(train_x), train_y),\n",
    "                \"test\" : r2_score(model.predict(test_x), test_y)\n",
    "            }\n",
    "        )\n",
    "effect_additional_trees_df = pd.DataFrame(effect_additional_trees)\n",
    "effect_additional_trees_df = effect_additional_trees_df.melt(\n",
    "    id_vars = ['number of trees', \"depth\"],\n",
    "    var_name = 'set',\n",
    "    value_name = 'r_squared'\n",
    ")\n",
    "effect_additional_trees_df[\"outcome\"] = effect_additional_trees_df.apply(\n",
    "    lambda x: \"depth: \" + str(x[\"depth\"]) + \", set: \" + x[\"set\"],\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var spec = {\"selection\": {\"selector010\": {\"bind\": \"scales\", \"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}}, \"encoding\": {\"color\": {\"field\": \"outcome\", \"scale\": {\"scheme\": \"category20\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"r_squared\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"number of trees\", \"type\": \"quantitative\"}}, \"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"mark\": \"line\", \"datasets\": {\"data-d29cebd1a884afa506d0f713edd7aaeb\": [{\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.1553572881249079, \"number of trees\": 5, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.5088807898611222, \"number of trees\": 5, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.5869936395003023, \"number of trees\": 5, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.8503120239488002, \"number of trees\": 5, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.41687585592923015, \"number of trees\": 15, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.7161689724072453, \"number of trees\": 15, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8537924140941628, \"number of trees\": 15, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.8910524671421225, \"number of trees\": 15, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.4743269097596986, \"number of trees\": 25, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.7528847508970448, \"number of trees\": 25, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8811374615922347, \"number of trees\": 25, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.8983629690541861, \"number of trees\": 25, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.4715368568198284, \"number of trees\": 35, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.7608002491473566, \"number of trees\": 35, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8814631225910393, \"number of trees\": 35, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9012518868702551, \"number of trees\": 35, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5004204820583051, \"number of trees\": 45, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.7672052962872455, \"number of trees\": 45, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8873313273857412, \"number of trees\": 45, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9017532380088307, \"number of trees\": 45, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5113861264104844, \"number of trees\": 55, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8055937828821681, \"number of trees\": 55, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8901570730810197, \"number of trees\": 55, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9067038813104187, \"number of trees\": 55, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5192224995643528, \"number of trees\": 65, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8094156835277538, \"number of trees\": 65, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8959559477332586, \"number of trees\": 65, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9083937336171621, \"number of trees\": 65, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.529750622116939, \"number of trees\": 75, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8160145670776926, \"number of trees\": 75, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8971778745075952, \"number of trees\": 75, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9072768377679234, \"number of trees\": 75, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5363611252907061, \"number of trees\": 85, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8276304522076329, \"number of trees\": 85, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8974691381100182, \"number of trees\": 85, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9073875717078821, \"number of trees\": 85, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5415195123463481, \"number of trees\": 95, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8325149140255282, \"number of trees\": 95, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.8977076628311197, \"number of trees\": 95, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9077847589440884, \"number of trees\": 95, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.544866538409352, \"number of trees\": 105, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8383687378199408, \"number of trees\": 105, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.900468043970693, \"number of trees\": 105, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9076591843824523, \"number of trees\": 105, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5464636557499485, \"number of trees\": 115, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8415572109132775, \"number of trees\": 115, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9008250756320043, \"number of trees\": 115, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9074451667763783, \"number of trees\": 115, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5496749240278582, \"number of trees\": 125, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8443905598743532, \"number of trees\": 125, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9010854476607985, \"number of trees\": 125, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9079785117300719, \"number of trees\": 125, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5439183163246812, \"number of trees\": 135, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8537213909602688, \"number of trees\": 135, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9021203965975304, \"number of trees\": 135, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9083919885303308, \"number of trees\": 135, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5503953774041161, \"number of trees\": 145, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8550599228242749, \"number of trees\": 145, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.902336859546996, \"number of trees\": 145, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9083735176162451, \"number of trees\": 145, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5491242466598453, \"number of trees\": 155, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8582761215549553, \"number of trees\": 155, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.902352563880079, \"number of trees\": 155, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9077892865954862, \"number of trees\": 155, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5525162586680369, \"number of trees\": 165, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8596976207264103, \"number of trees\": 165, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9028460914354149, \"number of trees\": 165, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9078656269063389, \"number of trees\": 165, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.55161026342697, \"number of trees\": 175, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8648181935374916, \"number of trees\": 175, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9021558096518878, \"number of trees\": 175, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9078964764943167, \"number of trees\": 175, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5498134547482619, \"number of trees\": 185, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.864558454313216, \"number of trees\": 185, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9039677853375889, \"number of trees\": 185, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.908051735033774, \"number of trees\": 185, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5507911660986629, \"number of trees\": 195, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8646974941690596, \"number of trees\": 195, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9044954820718173, \"number of trees\": 195, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9078743544307767, \"number of trees\": 195, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5558025414848954, \"number of trees\": 205, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8654397269378338, \"number of trees\": 205, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9052185720108888, \"number of trees\": 205, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9075679289600007, \"number of trees\": 205, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5574734931389703, \"number of trees\": 215, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8659979112250614, \"number of trees\": 215, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9058376425032817, \"number of trees\": 215, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9076523241673417, \"number of trees\": 215, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.557780828134566, \"number of trees\": 225, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8679443264820057, \"number of trees\": 225, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9060436920902066, \"number of trees\": 225, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9068736371074168, \"number of trees\": 225, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5564730556868132, \"number of trees\": 235, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8676602988528926, \"number of trees\": 235, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9052077552911861, \"number of trees\": 235, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9075550429138504, \"number of trees\": 235, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5559900579502116, \"number of trees\": 245, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8692777820883214, \"number of trees\": 245, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9062940631846977, \"number of trees\": 245, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9079472060234487, \"number of trees\": 245, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5573723943054647, \"number of trees\": 255, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8751688265360624, \"number of trees\": 255, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9061208152192335, \"number of trees\": 255, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.908212526499991, \"number of trees\": 255, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.556321167161126, \"number of trees\": 265, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8757636624702051, \"number of trees\": 265, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9062283384716527, \"number of trees\": 265, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.907651879717735, \"number of trees\": 265, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5558494630008439, \"number of trees\": 275, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8755516850035013, \"number of trees\": 275, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9060360444707439, \"number of trees\": 275, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9077343434867258, \"number of trees\": 275, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5592740821206266, \"number of trees\": 285, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.8763702276721455, \"number of trees\": 285, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9064680566978615, \"number of trees\": 285, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.9078923542705806, \"number of trees\": 285, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: test\", \"r_squared\": 0.5587727302453608, \"number of trees\": 295, \"set\": \"test\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: test\", \"r_squared\": 0.876862134759987, \"number of trees\": 295, \"set\": \"test\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: test\", \"r_squared\": 0.9068450386941603, \"number of trees\": 295, \"set\": \"test\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: test\", \"r_squared\": 0.907171084840212, \"number of trees\": 295, \"set\": \"test\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.16319673883379038, \"number of trees\": 5, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.509984074036026, \"number of trees\": 5, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.6042230612046404, \"number of trees\": 5, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.8579964332750216, \"number of trees\": 5, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.4234950435028221, \"number of trees\": 15, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.721350206681983, \"number of trees\": 15, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.8585498208882223, \"number of trees\": 15, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9061466936460724, \"number of trees\": 15, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.4795892664874357, \"number of trees\": 25, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.7572896285861168, \"number of trees\": 25, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.8861174228742241, \"number of trees\": 25, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.918123516143539, \"number of trees\": 25, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.4737496761635055, \"number of trees\": 35, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.7654709686391745, \"number of trees\": 35, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.8913177619811729, \"number of trees\": 35, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9256694624123839, \"number of trees\": 35, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5016946382192421, \"number of trees\": 45, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.7718312494978317, \"number of trees\": 45, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9002128963982445, \"number of trees\": 45, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9300937475822989, \"number of trees\": 45, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5100067960186405, \"number of trees\": 55, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8118218515070067, \"number of trees\": 55, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9044856660920182, \"number of trees\": 55, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9352103669463492, \"number of trees\": 55, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5170480754137016, \"number of trees\": 65, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8162771576073267, \"number of trees\": 65, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9103844720476161, \"number of trees\": 65, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.938874700819858, \"number of trees\": 65, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5261437627104676, \"number of trees\": 75, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8238204856581429, \"number of trees\": 75, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9128101534237728, \"number of trees\": 75, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9418110382932232, \"number of trees\": 75, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5346289459252829, \"number of trees\": 85, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8355294570926576, \"number of trees\": 85, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9153051942955603, \"number of trees\": 85, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9433082109941151, \"number of trees\": 85, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5385222300547674, \"number of trees\": 95, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8406965271062868, \"number of trees\": 95, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.918086979639325, \"number of trees\": 95, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9454699326848053, \"number of trees\": 95, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5417704363434219, \"number of trees\": 105, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8480014003280831, \"number of trees\": 105, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9215973821177486, \"number of trees\": 105, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9471537520330616, \"number of trees\": 105, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.544732371254329, \"number of trees\": 115, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8516870828693067, \"number of trees\": 115, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9226948746178364, \"number of trees\": 115, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9489053265497764, \"number of trees\": 115, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5473129600154562, \"number of trees\": 125, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8548353835973284, \"number of trees\": 125, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9247793996993936, \"number of trees\": 125, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9501817772913889, \"number of trees\": 125, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5420977037379313, \"number of trees\": 135, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8638629113359184, \"number of trees\": 135, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9259438913674795, \"number of trees\": 135, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9514939573516521, \"number of trees\": 135, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.54809270181869, \"number of trees\": 145, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8664654788315573, \"number of trees\": 145, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9271990990039198, \"number of trees\": 145, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9531155830931912, \"number of trees\": 145, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5464751317113031, \"number of trees\": 155, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8698309160622488, \"number of trees\": 155, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9284271847605977, \"number of trees\": 155, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9542788634096993, \"number of trees\": 155, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5501713567523638, \"number of trees\": 165, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8717523856793159, \"number of trees\": 165, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9290370007632094, \"number of trees\": 165, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9555323831825964, \"number of trees\": 165, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5496332674172135, \"number of trees\": 175, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8768893335868913, \"number of trees\": 175, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9299427974312833, \"number of trees\": 175, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9564126496099699, \"number of trees\": 175, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5473470818255919, \"number of trees\": 185, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8773176981479238, \"number of trees\": 185, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9317227470333259, \"number of trees\": 185, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9571486030788606, \"number of trees\": 185, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5480181379570009, \"number of trees\": 195, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8778795017785795, \"number of trees\": 195, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9323102645106535, \"number of trees\": 195, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9583306334469701, \"number of trees\": 195, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5531645163576222, \"number of trees\": 205, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8789596730028122, \"number of trees\": 205, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.933014175529773, \"number of trees\": 205, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9589348254648346, \"number of trees\": 205, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5551535485397454, \"number of trees\": 215, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8794177508534723, \"number of trees\": 215, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9343929025001867, \"number of trees\": 215, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9596475669709769, \"number of trees\": 215, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5559323946916835, \"number of trees\": 225, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8812918883798996, \"number of trees\": 225, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9345772262138539, \"number of trees\": 225, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9602934837227327, \"number of trees\": 225, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5542432257475286, \"number of trees\": 235, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8814402240610587, \"number of trees\": 235, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9353676401540673, \"number of trees\": 235, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.961351929487934, \"number of trees\": 235, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.553554623124612, \"number of trees\": 245, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8830585054351104, \"number of trees\": 245, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9363599329039135, \"number of trees\": 245, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9621430936485529, \"number of trees\": 245, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5553351358321925, \"number of trees\": 255, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.888486406079084, \"number of trees\": 255, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9370971083885126, \"number of trees\": 255, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9626030960653462, \"number of trees\": 255, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5549285241268346, \"number of trees\": 265, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8893673645985278, \"number of trees\": 265, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9377184896959692, \"number of trees\": 265, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9633315271928999, \"number of trees\": 265, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5543676535965987, \"number of trees\": 275, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8895087634850982, \"number of trees\": 275, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9381559201881138, \"number of trees\": 275, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.963881330035773, \"number of trees\": 275, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5579512930482653, \"number of trees\": 285, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8905249965165252, \"number of trees\": 285, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.938924708211006, \"number of trees\": 285, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9645764126167073, \"number of trees\": 285, \"set\": \"train\", \"depth\": 4}, {\"outcome\": \"depth: 1, set: train\", \"r_squared\": 0.5568298347510654, \"number of trees\": 295, \"set\": \"train\", \"depth\": 1}, {\"outcome\": \"depth: 2, set: train\", \"r_squared\": 0.8912150291746525, \"number of trees\": 295, \"set\": \"train\", \"depth\": 2}, {\"outcome\": \"depth: 3, set: train\", \"r_squared\": 0.9393517597847545, \"number of trees\": 295, \"set\": \"train\", \"depth\": 3}, {\"outcome\": \"depth: 4, set: train\", \"r_squared\": 0.9648744619466386, \"number of trees\": 295, \"set\": \"train\", \"depth\": 4}]}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"data\": {\"name\": \"data-d29cebd1a884afa506d0f713edd7aaeb\"}};\n",
       "var opt = {};\n",
       "var type = \"vega-lite\";\n",
       "var id = \"a023f378-a1e2-41c9-b1a9-3e71ece68e3a\";\n",
       "\n",
       "var output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  var target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  var style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x1a26e2ee10>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#a023f378-a1e2-41c9-b1a9-3e71ece68e3a"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "jupyter-vega": "#a023f378-a1e2-41c9-b1a9-3e71ece68e3a"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alt.Chart(effect_additional_trees_df).mark_line().encode(\n",
    "    x = \"number of trees:Q\",\n",
    "    y = \"r_squared:Q\",\n",
    "    color = alt.Color(\"outcome\", type=\"nominal\", scale = alt.Scale(scheme = \"category20\"))\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
